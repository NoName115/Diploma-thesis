{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "INPUT_SIZE = 25 * 3\n",
    "HIDDEN_SIZE = 1024 // 2\n",
    "EMBEDDING_INPUT_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "L2_WEIGTH_DECAY = 0.0001\n",
    "EPOCHS = 200\n",
    "\n",
    "LABELS = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 5,\n",
    "    7: 6,\n",
    "    8: 7,\n",
    "    9: 8,\n",
    "    10: 9,\n",
    "    11: 10,\n",
    "    13: 11,\n",
    "    15: 12,\n",
    "    17: 13,\n",
    "    19: 14,\n",
    "    20: 15,\n",
    "    22: 16,\n",
    "    23: 17,\n",
    "    25: 18,\n",
    "    28: 19,\n",
    "    29: 20,\n",
    "    30: 21,\n",
    "    31: 22,\n",
    "    32: 23,\n",
    "    33: 24,\n",
    "    34: 25,\n",
    "    35: 26,\n",
    "    36: 27,\n",
    "    37: 28,\n",
    "    38: 29,\n",
    "    39: 30,\n",
    "    40: 31,\n",
    "    41: 32,\n",
    "    42: 33,\n",
    "    43: 34,\n",
    "    44: 35,\n",
    "    45: 36,\n",
    "    46: 37,\n",
    "    47: 38,\n",
    "    48: 39,\n",
    "    49: 40,\n",
    "    50: 41,\n",
    "    51: 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterableMovementDataset(IterableDataset):\n",
    "\n",
    "    NUMBER_OF_JOINTS = 25\n",
    "    NUMBER_OF_AXES = 3\n",
    "    \n",
    "    def __init__(self, root: str, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.data_files = list(sorted(os.listdir(self.root)))\n",
    "        self.file_frames: List[int] = []\n",
    "        \n",
    "        self.classes = LABELS\n",
    "        \n",
    "        self.loaded_data = dict()\n",
    "        for file_name in self.data_files:\n",
    "            with open(os.path.join(self.root, file_name), \"r\") as f:\n",
    "                self.loaded_data[file_name] = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "    def _get_file_length(self, file_data: List[str]):\n",
    "        header = file_data[0].split()[-1].split(\"_\")\n",
    "        return int(header[-1])\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i, file_name in enumerate(self.data_files):\n",
    "            #action_file = os.path.join(self.root, file_name)\n",
    "            #with open(action_file, \"r\") as f:\n",
    "            #    data_str = f.read().rstrip('\\n').split('\\n')\n",
    "            data_str = self.loaded_data[file_name]\n",
    "            \n",
    "            sequence_length = self._get_file_length(data_str)\n",
    "            \n",
    "            all_frames = []\n",
    "            for frame in data_str[2:]:  # first two header lines in the file\n",
    "                all_frames.append(\n",
    "                    [triple.split(\", \") for triple in frame.split(\"; \")]\n",
    "                )\n",
    "            \n",
    "            all_frames = np.array(all_frames, dtype=np.float32)\n",
    "            '''\n",
    "            frame = np.array(\n",
    "                [\n",
    "                    triple.split(\", \") for triple in data_str[line_indx].split(\";\")\n",
    "                ],\n",
    "                dtype=np.float32\n",
    "            )\n",
    "            '''\n",
    "            assert all_frames.shape == (sequence_length, self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "\n",
    "            # get sequence label\n",
    "            label = self.classes[int(data_str[0].split()[-1].split(\"_\")[1])]\n",
    "            target = np.zeros(len(self.classes), dtype=np.float32)\n",
    "            target[label] = 1.0\n",
    "        \n",
    "            all_frames = torch.from_numpy(all_frames)\n",
    "        \n",
    "            #if self.transforms:\n",
    "            #    all_frames = self.transforms(all_frames)\n",
    "\n",
    "            yield all_frames, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, lstm_hidden_size: int, embedding_output_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = lstm_hidden_size\n",
    "        self.num_layers = 2  # bi-LSTM\n",
    "        \n",
    "        # Embedding part, from 75 -> 64 size\n",
    "        self.embedding = nn.Linear(input_size, embedding_output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_output_size, lstm_hidden_size, self.num_layers, batch_first=True, bidirectional=True)\n",
    "        self.do = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(self.hidden_size * self.num_layers, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Embedding\n",
    "        out = self.embedding(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        #print(f\"O: {out.size()}\")  # (143, 1, 64) (batch, seq, features)\n",
    "        #out = out.reshape(1, 1, -1)\n",
    "        \n",
    "        out, _ = self.lstm(out, (h0, c0))\n",
    "        \n",
    "        out = self.do(out[:, -1, :])\n",
    "        out = self.classifier(out)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataloader\n",
    "class MovementsDataset(Dataset):\n",
    "    \n",
    "    NUMBER_OF_JOINTS = 25\n",
    "    NUMBER_OF_AXES = 3\n",
    "    \n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.data_files = list(sorted(os.listdir(self.root)))\n",
    "        self.file_frames: List[int] = []\n",
    "\n",
    "        self.classes = LABELS\n",
    "        \n",
    "        # Load number of frames for every file\n",
    "        for fn in self.data_files:\n",
    "            with open(os.path.join(self.root, fn)) as f:\n",
    "                header = f.readline().split()[-1].split(\"_\")\n",
    "                \n",
    "                self.file_frames.append(int(header[-1]))  # last element - number_of_frames\n",
    "        \n",
    "    def _get_file_index(self, frame_indx) -> Tuple[int, int]:\n",
    "        start_indx = frame_indx\n",
    "        for i, nof in enumerate(self.file_frames):\n",
    "            if start_indx < nof:\n",
    "                # print(f\"{start_indx} - {i}\")\n",
    "                return i, start_indx\n",
    "            else:\n",
    "                start_indx -= nof\n",
    "        \n",
    "    def __getitem__(self, indx):\n",
    "        file_indx, line_indx = self._get_file_index(indx)\n",
    "        action_file = os.path.join(self.root, self.data_files[file_indx])\n",
    "        \n",
    "        with open(action_file, \"r\") as f:\n",
    "            data_str = f.read().rstrip('\\n').split('\\n')\n",
    "        \n",
    "        line_indx += 2  # first two header lines in the file   \n",
    "        frame = np.array([triple.split(\", \") for triple in data_str[line_indx].split(\";\")], dtype=np.float32)\n",
    "        assert frame.shape == (self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "        \n",
    "        target = self.classes[int(data_str[0].split()[-1].split(\"_\")[1])]\n",
    "        \n",
    "        if self.transforms:\n",
    "            frame = self.transforms(frame)\n",
    "        \n",
    "        return frame, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IterableMovementDataset(\n",
    "    \"../data/cross-view/train\",\n",
    ")\n",
    "test_dataset = IterableMovementDataset(\n",
    "    \"../data/cross-view/val\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1) #, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset) #, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up\n",
    "#  - Adam optimizer *\n",
    "#  - LR = 0.0005 *\n",
    "#  - batch = 1 *\n",
    "#  - L2 weight decay = 0.0001 *\n",
    "#  - dropout = 0.5 *\n",
    "#  - 200 epochs\n",
    "#  - Embedding - 64 *\n",
    "#  - Hidden-state - 1024 --> halved for Bi-LSTM *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name: str, epoch: int):\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    with open(\"last_checkpoint\", \"w\") as lf:\n",
    "        lf.write(str(epoch))\n",
    "    print(f\"Model saved into: {model_name}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with epoch: 0\n",
      "999/13207 -  Epoch [1/200], average_loss: 0.113635\n",
      "1998/13207 -  Epoch [1/200], average_loss: 0.113361\n",
      "2997/13207 -  Epoch [1/200], average_loss: 0.113285\n",
      "3996/13207 -  Epoch [1/200], average_loss: 0.113283\n",
      "4995/13207 -  Epoch [1/200], average_loss: 0.112483\n",
      "5994/13207 -  Epoch [1/200], average_loss: 0.112738\n",
      "6993/13207 -  Epoch [1/200], average_loss: 0.112629\n",
      "7992/13207 -  Epoch [1/200], average_loss: 0.117491\n",
      "8991/13207 -  Epoch [1/200], average_loss: 0.11219\n",
      "9990/13207 -  Epoch [1/200], average_loss: 0.111831\n",
      "10989/13207 -  Epoch [1/200], average_loss: 0.107128\n",
      "11988/13207 -  Epoch [1/200], average_loss: 0.100046\n",
      "12987/13207 -  Epoch [1/200], average_loss: 0.098777\n",
      "Evaluation time: 459.68922567367554s.\n",
      "999/13207 -  Epoch [2/200], average_loss: 0.103275\n",
      "1998/13207 -  Epoch [2/200], average_loss: 0.099607\n",
      "2997/13207 -  Epoch [2/200], average_loss: 0.097289\n",
      "3996/13207 -  Epoch [2/200], average_loss: 0.095844\n",
      "4995/13207 -  Epoch [2/200], average_loss: 0.094424\n",
      "5994/13207 -  Epoch [2/200], average_loss: 0.095383\n",
      "6993/13207 -  Epoch [2/200], average_loss: 0.092498\n",
      "7992/13207 -  Epoch [2/200], average_loss: 0.091922\n",
      "8991/13207 -  Epoch [2/200], average_loss: 0.091359\n",
      "9990/13207 -  Epoch [2/200], average_loss: 0.092707\n",
      "10989/13207 -  Epoch [2/200], average_loss: 0.087444\n",
      "11988/13207 -  Epoch [2/200], average_loss: 0.086141\n",
      "12987/13207 -  Epoch [2/200], average_loss: 0.086643\n",
      "Evaluation time: 455.19318199157715s.\n",
      "999/13207 -  Epoch [3/200], average_loss: 0.093638\n",
      "1998/13207 -  Epoch [3/200], average_loss: 0.088696\n",
      "2997/13207 -  Epoch [3/200], average_loss: 0.086294\n",
      "3996/13207 -  Epoch [3/200], average_loss: 0.095895\n",
      "4995/13207 -  Epoch [3/200], average_loss: 0.102946\n",
      "5994/13207 -  Epoch [3/200], average_loss: 0.088186\n",
      "6993/13207 -  Epoch [3/200], average_loss: 0.092144\n",
      "7992/13207 -  Epoch [3/200], average_loss: 0.08681\n",
      "8991/13207 -  Epoch [3/200], average_loss: 0.084679\n",
      "9990/13207 -  Epoch [3/200], average_loss: 0.085097\n",
      "10989/13207 -  Epoch [3/200], average_loss: 0.082537\n",
      "11988/13207 -  Epoch [3/200], average_loss: 0.080003\n",
      "12987/13207 -  Epoch [3/200], average_loss: 0.080113\n",
      "Evaluation time: 456.85938715934753s.\n",
      "999/13207 -  Epoch [4/200], average_loss: 0.085153\n",
      "1998/13207 -  Epoch [4/200], average_loss: 0.092071\n",
      "2997/13207 -  Epoch [4/200], average_loss: 0.082639\n",
      "3996/13207 -  Epoch [4/200], average_loss: 0.077506\n",
      "4995/13207 -  Epoch [4/200], average_loss: 0.086067\n",
      "5994/13207 -  Epoch [4/200], average_loss: 0.085978\n",
      "6993/13207 -  Epoch [4/200], average_loss: 0.078789\n",
      "7992/13207 -  Epoch [4/200], average_loss: 0.077174\n",
      "8991/13207 -  Epoch [4/200], average_loss: 0.078549\n",
      "9990/13207 -  Epoch [4/200], average_loss: 0.079364\n",
      "10989/13207 -  Epoch [4/200], average_loss: 0.077028\n",
      "11988/13207 -  Epoch [4/200], average_loss: 0.076009\n",
      "12987/13207 -  Epoch [4/200], average_loss: 0.076175\n",
      "Evaluation time: 457.3466420173645s.\n",
      "999/13207 -  Epoch [5/200], average_loss: 0.086181\n",
      "1998/13207 -  Epoch [5/200], average_loss: 0.07936\n",
      "2997/13207 -  Epoch [5/200], average_loss: 0.07619\n",
      "3996/13207 -  Epoch [5/200], average_loss: 0.075085\n",
      "4995/13207 -  Epoch [5/200], average_loss: 0.076782\n",
      "5994/13207 -  Epoch [5/200], average_loss: 0.074798\n",
      "6993/13207 -  Epoch [5/200], average_loss: 0.072167\n",
      "7992/13207 -  Epoch [5/200], average_loss: 0.071473\n",
      "8991/13207 -  Epoch [5/200], average_loss: 0.074263\n",
      "9990/13207 -  Epoch [5/200], average_loss: 0.073541\n",
      "10989/13207 -  Epoch [5/200], average_loss: 0.071408\n",
      "11988/13207 -  Epoch [5/200], average_loss: 0.067256\n",
      "12987/13207 -  Epoch [5/200], average_loss: 0.089581\n",
      "Evaluation time: 458.2019100189209s.\n",
      "999/13207 -  Epoch [6/200], average_loss: 0.080438\n",
      "1998/13207 -  Epoch [6/200], average_loss: 0.071975\n",
      "2997/13207 -  Epoch [6/200], average_loss: 0.069024\n",
      "3996/13207 -  Epoch [6/200], average_loss: 0.069825\n",
      "4995/13207 -  Epoch [6/200], average_loss: 0.068928\n",
      "5994/13207 -  Epoch [6/200], average_loss: 0.075371\n",
      "6993/13207 -  Epoch [6/200], average_loss: 0.071009\n",
      "7992/13207 -  Epoch [6/200], average_loss: 0.087883\n",
      "8991/13207 -  Epoch [6/200], average_loss: 0.117305\n",
      "9990/13207 -  Epoch [6/200], average_loss: 0.086778\n",
      "10989/13207 -  Epoch [6/200], average_loss: 0.075672\n",
      "11988/13207 -  Epoch [6/200], average_loss: 0.073194\n",
      "12987/13207 -  Epoch [6/200], average_loss: 0.070624\n",
      "Evaluation time: 457.96512269973755s.\n",
      "999/13207 -  Epoch [7/200], average_loss: 0.092824\n",
      "1998/13207 -  Epoch [7/200], average_loss: 0.073306\n",
      "2997/13207 -  Epoch [7/200], average_loss: 0.068209\n",
      "3996/13207 -  Epoch [7/200], average_loss: 0.068557\n",
      "4995/13207 -  Epoch [7/200], average_loss: 0.066895\n",
      "5994/13207 -  Epoch [7/200], average_loss: 0.070063\n",
      "6993/13207 -  Epoch [7/200], average_loss: 0.068343\n",
      "7992/13207 -  Epoch [7/200], average_loss: 0.067297\n",
      "8991/13207 -  Epoch [7/200], average_loss: 0.072199\n",
      "9990/13207 -  Epoch [7/200], average_loss: 0.07113\n",
      "10989/13207 -  Epoch [7/200], average_loss: 0.068079\n",
      "11988/13207 -  Epoch [7/200], average_loss: 0.063869\n",
      "12987/13207 -  Epoch [7/200], average_loss: 0.06317\n",
      "Evaluation time: 460.99031472206116s.\n",
      "999/13207 -  Epoch [8/200], average_loss: 0.072864\n",
      "1998/13207 -  Epoch [8/200], average_loss: 0.069927\n",
      "2997/13207 -  Epoch [8/200], average_loss: 0.063516\n",
      "3996/13207 -  Epoch [8/200], average_loss: 0.062197\n",
      "4995/13207 -  Epoch [8/200], average_loss: 0.064491\n",
      "5994/13207 -  Epoch [8/200], average_loss: 0.065453\n",
      "6993/13207 -  Epoch [8/200], average_loss: 0.067543\n",
      "7992/13207 -  Epoch [8/200], average_loss: 0.065978\n",
      "8991/13207 -  Epoch [8/200], average_loss: 0.06811\n",
      "9990/13207 -  Epoch [8/200], average_loss: 0.06479\n",
      "10989/13207 -  Epoch [8/200], average_loss: 0.062512\n",
      "11988/13207 -  Epoch [8/200], average_loss: 0.061206\n",
      "12987/13207 -  Epoch [8/200], average_loss: 0.065316\n",
      "Evaluation time: 461.6021842956543s.\n",
      "999/13207 -  Epoch [9/200], average_loss: 0.072053\n",
      "1998/13207 -  Epoch [9/200], average_loss: 0.067227\n",
      "2997/13207 -  Epoch [9/200], average_loss: 0.06258\n",
      "3996/13207 -  Epoch [9/200], average_loss: 0.057934\n",
      "4995/13207 -  Epoch [9/200], average_loss: 0.062476\n",
      "5994/13207 -  Epoch [9/200], average_loss: 0.062975\n",
      "6993/13207 -  Epoch [9/200], average_loss: 0.063261\n",
      "7992/13207 -  Epoch [9/200], average_loss: 0.062161\n",
      "8991/13207 -  Epoch [9/200], average_loss: 0.065352\n",
      "9990/13207 -  Epoch [9/200], average_loss: 0.073058\n",
      "10989/13207 -  Epoch [9/200], average_loss: 0.063661\n",
      "11988/13207 -  Epoch [9/200], average_loss: 0.060391\n",
      "12987/13207 -  Epoch [9/200], average_loss: 0.058763\n",
      "Evaluation time: 459.71051263809204s.\n",
      "999/13207 -  Epoch [10/200], average_loss: 0.068062\n",
      "1998/13207 -  Epoch [10/200], average_loss: 0.061234\n",
      "2997/13207 -  Epoch [10/200], average_loss: 0.063981\n",
      "3996/13207 -  Epoch [10/200], average_loss: 0.058001\n",
      "4995/13207 -  Epoch [10/200], average_loss: 0.060917\n",
      "5994/13207 -  Epoch [10/200], average_loss: 0.060959\n",
      "6993/13207 -  Epoch [10/200], average_loss: 0.060106\n",
      "7992/13207 -  Epoch [10/200], average_loss: 0.06025\n",
      "8991/13207 -  Epoch [10/200], average_loss: 0.062837\n",
      "9990/13207 -  Epoch [10/200], average_loss: 0.065652\n",
      "10989/13207 -  Epoch [10/200], average_loss: 0.062334\n",
      "11988/13207 -  Epoch [10/200], average_loss: 0.056018\n",
      "12987/13207 -  Epoch [10/200], average_loss: 0.056985\n",
      "Evaluation time: 459.3479917049408s.\n",
      "Model saved into: model.pth\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "model = BiRNN(INPUT_SIZE, HIDDEN_SIZE, EMBEDDING_INPUT_SIZE, len(train_dataset.classes)).to(device)\n",
    "\n",
    "start_epoch = 0\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "    with open(\"last_checkpoint\", \"r\") as lf:\n",
    "        start_epoch = int(lf.read())\n",
    "    print(f\"Model loaded with epoch: {start_epoch}\")\n",
    "else:\n",
    "    print(\"Pretrained model not found\")\n",
    "\n",
    "SAVE_CHECHPOINT = 50\n",
    "PRINT_STEP = 999\n",
    "board_writer = SummaryWriter()\n",
    "\n",
    "criterion = nn.BCELoss()  #nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=L2_WEIGTH_DECAY\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(start_epoch, start_epoch + 90):  #EPOCHS):\n",
    "    s_time = time.time()\n",
    "    total_loss = 0.0\n",
    "    total_iterations_per_epoch = len(train_loader)\n",
    "    \n",
    "    for i, (sequence, labels) in enumerate(train_loader, 1):\n",
    "        #print(sequence.shape)\n",
    "        #print(labels.shape)\n",
    "\n",
    "        # (batch, seq_len, num_of_features)\n",
    "        sequence = sequence.view(sequence.size(0), sequence.size(1), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #print(sequence.shape)\n",
    "        #print(labels.shape)\n",
    "        #break\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(sequence)\n",
    "        \n",
    "        #print(outputs.shape)\n",
    "        #print(labels.shape)\n",
    "        #break\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        #print(total_loss)\n",
    "        #break\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % PRINT_STEP == 0:\n",
    "            average_loss = total_loss / PRINT_STEP\n",
    "            print(f\"{i}/{len(train_loader)} -  Epoch [{epoch + 1}/{EPOCHS}], average_loss: {round(average_loss, 6)}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "            board_writer.add_scalar(\n",
    "                'Average_Loss/train',\n",
    "                average_loss,\n",
    "                (epoch * total_iterations_per_epoch) + i\n",
    "            )\n",
    "\n",
    "    print(f\"Evaluation time: {time.time() - s_time}s.\")\n",
    "\n",
    "    if (epoch + 1) % SAVE_CHECHPOINT == 0:\n",
    "        save_model(model, f\"model_{epoch}\", epoch)\n",
    "\n",
    "save_model(model, \"model\", epoch)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model(model, \"model\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(dict_results, total_records):\n",
    "    with open(\"model_results.json\", \"w\") as jf:\n",
    "        json.dump({\n",
    "            \"thresholds\": dict_results,\n",
    "            \"total_records\": total_records\n",
    "        }, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: [0/837]\n",
      "Processed: [49/837]\n",
      "Processed: [98/837]\n",
      "Processed: [147/837]\n",
      "Processed: [196/837]\n",
      "Processed: [245/837]\n",
      "Processed: [294/837]\n",
      "Processed: [343/837]\n",
      "Processed: [392/837]\n",
      "Processed: [441/837]\n",
      "Processed: [490/837]\n",
      "Processed: [539/837]\n",
      "Processed: [588/837]\n",
      "Processed: [637/837]\n",
      "Processed: [686/837]\n",
      "Processed: [735/837]\n",
      "Processed: [784/837]\n",
      "Processed: [833/837]\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "with torch.no_grad():\n",
    "    steps = 20\n",
    "    def_dict = {\n",
    "        \"correct\": 0,\n",
    "        \"above\": 0,\n",
    "    }\n",
    "    thresholds = [(round((1 / steps) * (i + 1), 4), def_dict.copy()) for i in range(steps)]\n",
    "    total = 0\n",
    "\n",
    "    for i, (sequence, labels) in enumerate(test_loader):\n",
    "        sequence = sequence.view(sequence.size(0), sequence.size(1), -1).to(device)\n",
    "        label_id = torch.argmax(labels).item()\n",
    "        \n",
    "        outputs = model(sequence)\n",
    "\n",
    "        for val_th, res_dict in thresholds:\n",
    "            res_dict[\"above\"] += (outputs.data > val_th).sum().item()\n",
    "\n",
    "            # Correctly predicted\n",
    "            for _, label_true_indx in zip(*torch.where(outputs.data > val_th)):\n",
    "                if label_true_indx == label_id:\n",
    "                    res_dict[\"correct\"] += 1\n",
    "        \n",
    "        total += 1 # labels.size(0)\n",
    "\n",
    "        if i % 49 == 0:\n",
    "            print(f\"Processed: [{i}/{len(test_dataset)}]\")\n",
    "\n",
    "# Save dictionary results\n",
    "save_results(thresholds, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(thresholds, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "with open(\"model_cv/model_results.json\", \"r\") as jf:\n",
    "    data = json.load(jf)\n",
    "\n",
    "thresholds = data[\"thresholds\"]\n",
    "total = data[\"total_records\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------0.05---------------\n",
      "Test Precision: 21.0055%\n",
      "Test Recall: 86.8578%\n",
      "Test f1_score: 0.3383\n",
      "\n",
      "---------------0.1---------------\n",
      "Test Precision: 29.4722%\n",
      "Test Recall: 75.3883%\n",
      "Test f1_score: 0.4238\n",
      "\n",
      "---------------0.15---------------\n",
      "Test Precision: 35.036%\n",
      "Test Recall: 63.9188%\n",
      "Test f1_score: 0.4526\n",
      "\n",
      "---------------0.2---------------\n",
      "Test Precision: 39.3707%\n",
      "Test Recall: 55.3166%\n",
      "Test f1_score: 0.46\n",
      "\n",
      "---------------0.25---------------\n",
      "Test Precision: 44.8619%\n",
      "Test Recall: 48.5066%\n",
      "Test f1_score: 0.4661\n",
      "\n",
      "---------------0.3---------------\n",
      "Test Precision: 49.0541%\n",
      "Test Recall: 43.3692%\n",
      "Test f1_score: 0.4604\n",
      "\n",
      "---------------0.35---------------\n",
      "Test Precision: 52.3179%\n",
      "Test Recall: 37.7539%\n",
      "Test f1_score: 0.4386\n",
      "\n",
      "---------------0.4---------------\n",
      "Test Precision: 55.3753%\n",
      "Test Recall: 32.6165%\n",
      "Test f1_score: 0.4105\n",
      "\n",
      "---------------0.45---------------\n",
      "Test Precision: 60.7046%\n",
      "Test Recall: 26.7622%\n",
      "Test f1_score: 0.3715\n",
      "\n",
      "---------------0.5---------------\n",
      "Test Precision: 64.8649%\n",
      "Test Recall: 22.9391%\n",
      "Test f1_score: 0.3389\n",
      "\n",
      "---------------0.55---------------\n",
      "Test Precision: 69.5833%\n",
      "Test Recall: 19.9522%\n",
      "Test f1_score: 0.3101\n",
      "\n",
      "---------------0.6---------------\n",
      "Test Precision: 75.3846%\n",
      "Test Recall: 17.5627%\n",
      "Test f1_score: 0.2849\n",
      "\n",
      "---------------0.65---------------\n",
      "Test Precision: 80.3922%\n",
      "Test Recall: 14.6953%\n",
      "Test f1_score: 0.2485\n",
      "\n",
      "---------------0.7---------------\n",
      "Test Precision: 83.9623%\n",
      "Test Recall: 10.6332%\n",
      "Test f1_score: 0.1888\n",
      "\n",
      "---------------0.75---------------\n",
      "Test Precision: 87.9518%\n",
      "Test Recall: 8.7216%\n",
      "Test f1_score: 0.1587\n",
      "\n",
      "---------------0.8---------------\n",
      "Test Precision: 88.6792%\n",
      "Test Recall: 5.6153%\n",
      "Test f1_score: 0.1056\n",
      "\n",
      "---------------0.85---------------\n",
      "Test Precision: 97.1429%\n",
      "Test Recall: 4.0621%\n",
      "Test f1_score: 0.078\n",
      "\n",
      "---------------0.9---------------\n",
      "Test Precision: 100.0%\n",
      "Test Recall: 3.3453%\n",
      "Test f1_score: 0.0647\n",
      "\n",
      "---------------0.95---------------\n",
      "Test Precision: 100.0%\n",
      "Test Recall: 2.0311%\n",
      "Test f1_score: 0.0398\n",
      "--------------------------------\n",
      "-------------- AP --------------\n",
      "AP: 0.6399\n"
     ]
    }
   ],
   "source": [
    "# Calculation of evalution metrics for every threshold\n",
    "ap_score = 0\n",
    "old_recall = 0\n",
    "for th, values in thresholds[:-1]:\n",
    "    recall = values[\"correct\"] / total\n",
    "\n",
    "    if values[\"above\"] > 0:\n",
    "        precision = values[\"correct\"] / values[\"above\"]\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        precision = 0\n",
    "        f1_score = 0\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 15 + f\"{th}\" + \"-\" * 15)\n",
    "    print(f\"Test Precision: {round(100 * precision, 4)}%\")\n",
    "    print(f\"Test Recall: {round(100 * recall, 4)}%\")\n",
    "    print(f\"Test f1_score: {round(f1_score, 4)}\")\n",
    "\n",
    "    ap_score += ((abs(recall - old_recall)) * precision)\n",
    "    old_recall = recall\n",
    "\n",
    "# AP - score\n",
    "print(\"-\" * 32)\n",
    "print(\"-\" * 14 + \" AP \" + \"-\" * 14)\n",
    "print(f\"AP: {round(ap_score, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#  - evaluacne metriky\n",
    "#  - format dat pre trenovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Evalution metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "#  - Precision: the ratio of correctly annotated frames and all the model-annotated frames on test sequences\n",
    "#  - spravne anotovane (correctly annotates)\n",
    "#  - zoberiem threshold pre kazdy output v kazdom snimku --> pocet tried do ktorych sa klasifikoval snimok (all model-annotated frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
