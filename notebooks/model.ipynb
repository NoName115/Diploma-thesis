{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "INPUT_SIZE = 25 * 3\n",
    "HIDDEN_SIZE = 1024 // 2\n",
    "EMBEDDING_INPUT_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.0005\n",
    "L2_WEIGTH_DECAY = 0.0001\n",
    "EPOCHS = 200\n",
    "\n",
    "LABELS = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "    3: 2,\n",
    "    4: 3,\n",
    "    5: 4,\n",
    "    6: 5,\n",
    "    7: 6,\n",
    "    8: 7,\n",
    "    9: 8,\n",
    "    10: 9,\n",
    "    11: 10,\n",
    "    13: 11,\n",
    "    15: 12,\n",
    "    17: 13,\n",
    "    19: 14,\n",
    "    20: 15,\n",
    "    22: 16,\n",
    "    23: 17,\n",
    "    25: 18,\n",
    "    28: 19,\n",
    "    29: 20,\n",
    "    30: 21,\n",
    "    31: 22,\n",
    "    32: 23,\n",
    "    33: 24,\n",
    "    34: 25,\n",
    "    35: 26,\n",
    "    36: 27,\n",
    "    37: 28,\n",
    "    38: 29,\n",
    "    39: 30,\n",
    "    40: 31,\n",
    "    41: 32,\n",
    "    42: 33,\n",
    "    43: 34,\n",
    "    44: 35,\n",
    "    45: 36,\n",
    "    46: 37,\n",
    "    47: 38,\n",
    "    48: 39,\n",
    "    49: 40,\n",
    "    50: 41,\n",
    "    51: 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterableMovementDataset(IterableDataset):\n",
    "    \n",
    "    NUMBER_OF_JOINTS = 25\n",
    "    NUMBER_OF_AXES = 3\n",
    "    \n",
    "    def __init__(self, root: str, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.data_files = list(sorted(os.listdir(self.root)))\n",
    "        self.file_frames: List[int] = []\n",
    "        \n",
    "        self.classes = LABELS\n",
    "        \n",
    "        self.loaded_data = dict()\n",
    "        for file_name in self.data_files:\n",
    "            with open(os.path.join(self.root, file_name), \"r\") as f:\n",
    "                self.loaded_data[file_name] = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "    def _get_file_length(self, file_data: List[str]):\n",
    "        header = file_data[0].split()[-1].split(\"_\")\n",
    "        return int(header[-1])\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i, file_name in enumerate(self.data_files):\n",
    "            #action_file = os.path.join(self.root, file_name)\n",
    "            #with open(action_file, \"r\") as f:\n",
    "            #    data_str = f.read().rstrip('\\n').split('\\n')\n",
    "            data_str = self.loaded_data[file_name]\n",
    "            \n",
    "            sequence_length = self._get_file_length(data_str)\n",
    "            \n",
    "            all_frames = []\n",
    "            for frame in data_str[2:]:  # first two header lines in the file\n",
    "                all_frames.append(\n",
    "                    [triple.split(\", \") for triple in frame.split(\"; \")]\n",
    "                )\n",
    "            \n",
    "            all_frames = np.array(all_frames, dtype=np.float32)\n",
    "            '''\n",
    "            frame = np.array(\n",
    "                [\n",
    "                    triple.split(\", \") for triple in data_str[line_indx].split(\";\")\n",
    "                ],\n",
    "                dtype=np.float32\n",
    "            )\n",
    "            '''\n",
    "            assert all_frames.shape == (sequence_length, self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "    \n",
    "            # get sequence label\n",
    "            target = [self.classes[int(data_str[0].split()[-1].split(\"_\")[1])]] * sequence_length\n",
    "            target = np.array(target)\n",
    "        \n",
    "            if self.transforms:\n",
    "                all_frames = self.transforms(all_frames)\n",
    "\n",
    "            yield all_frames, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size: int, hidden_size: int, linear_input_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = 2\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, self.num_layers, batch_first=True, bidirectional=True)\n",
    "        self.embedding = nn.Linear(self.hidden_size * 2, linear_input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.do = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(linear_input_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        # Forward to LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # output format: (batch_size, seq_length, hidden_size * 2)\n",
    "        out = self.embedding(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.do(out)\n",
    "        out = self.classifier(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewBiRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size: int, lstm_hidden_size: int, embedding_output_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.hidden_size = lstm_hidden_size\n",
    "        self.num_layers = 2  # bi-LSTM\n",
    "        \n",
    "        # Embedding part, from 75 -> 64 size\n",
    "        self.embedding = nn.Linear(input_size, embedding_output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_output_size, lstm_hidden_size, self.num_layers, batch_first=True, bidirectional=True)\n",
    "        self.do = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(self.hidden_size * self.num_layers, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Embedding\n",
    "        out = self.embedding(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # Bi-LSTM\n",
    "        out, _ = self.lstm(out, (h0, c0))\n",
    "        \n",
    "        out = self.do(out[:, -1, :])\n",
    "        out = self.classifier(out)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataloader\n",
    "class MovementsDataset(Dataset):\n",
    "    \n",
    "    NUMBER_OF_JOINTS = 25\n",
    "    NUMBER_OF_AXES = 3\n",
    "    \n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.data_files = list(sorted(os.listdir(self.root)))\n",
    "        self.file_frames: List[int] = []\n",
    "\n",
    "        self.classes = LABELS\n",
    "        \n",
    "        # Load number of frames for every file\n",
    "        for fn in self.data_files:\n",
    "            with open(os.path.join(self.root, fn)) as f:\n",
    "                header = f.readline().split()[-1].split(\"_\")\n",
    "                \n",
    "                self.file_frames.append(int(header[-1]))  # last element - number_of_frames\n",
    "        \n",
    "    def _get_file_index(self, frame_indx) -> Tuple[int, int]:\n",
    "        start_indx = frame_indx\n",
    "        for i, nof in enumerate(self.file_frames):\n",
    "            if start_indx < nof:\n",
    "                # print(f\"{start_indx} - {i}\")\n",
    "                return i, start_indx\n",
    "            else:\n",
    "                start_indx -= nof\n",
    "        \n",
    "    def __getitem__(self, indx):\n",
    "        file_indx, line_indx = self._get_file_index(indx)\n",
    "        action_file = os.path.join(self.root, self.data_files[file_indx])\n",
    "        \n",
    "        with open(action_file, \"r\") as f:\n",
    "            data_str = f.read().rstrip('\\n').split('\\n')\n",
    "        \n",
    "        line_indx += 2  # first two header lines in the file   \n",
    "        frame = np.array([triple.split(\", \") for triple in data_str[line_indx].split(\";\")], dtype=np.float32)\n",
    "        assert frame.shape == (self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "        \n",
    "        target = self.classes[int(data_str[0].split()[-1].split(\"_\")[1])]\n",
    "        \n",
    "        if self.transforms:\n",
    "            frame = self.transforms(frame)\n",
    "        \n",
    "        return frame, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = IterableMovementDataset(\n",
    "    \"../data/cross-view/train\",\n",
    "    transforms=transforms.ToTensor()\n",
    ")\n",
    "test_dataset = IterableMovementDataset(\n",
    "    \"../data/cross-view/val\",\n",
    "    transforms=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset) #, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset) #, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up\n",
    "#  - Adam optimizer *\n",
    "#  - LR = 0.0005 *\n",
    "#  - batch = 1 *\n",
    "#  - L2 weight decay = 0.0001 *\n",
    "#  - dropout = 0.5 *\n",
    "#  - 200 epochs\n",
    "#  - Embedding - 64 *\n",
    "#  - Hidden-state - 1024 --> halved for Bi-LSTM *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name: str, epoch: int):\n",
    "    torch.save(model.state_dict(), f\"{model_name}.pth\")\n",
    "    with open(\"last_checkpoint\", \"w\") as lf:\n",
    "        lf.write(str(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained model not found\n",
      "999/13207 -  Epoch [1/200], average_loss: 3.7777\n",
      "1998/13207 -  Epoch [1/200], average_loss: 3.6732\n",
      "2997/13207 -  Epoch [1/200], average_loss: 3.609\n",
      "3996/13207 -  Epoch [1/200], average_loss: 3.5853\n"
     ]
    }
   ],
   "source": [
    "# Training the network\n",
    "#model = BiRNN(75, HIDDEN_SIZE, LINEAR_INPUT_SIZE, len(train_dataset.classes)).to(device)\n",
    "model = NewBiRNN(INPUT_SIZE, HIDDEN_SIZE, EMBEDDING_INPUT_SIZE, len(train_dataset.classes)).to(device)\n",
    "\n",
    "start_epoch = 0\n",
    "if os.path.exists(\"model.pth\"):\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "    with open(\"last_checkpoint\", \"r\") as lf:\n",
    "        start_epoch = int(lf.read())\n",
    "    print(f\"Model loaded with epoch: {start_epoch}\")\n",
    "else:\n",
    "    print(\"Pretrained model not found\")\n",
    "\n",
    "SAVE_CHECHPOINT = 50\n",
    "PRINT_STEP = 999\n",
    "board_writer = SummaryWriter()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=L2_WEIGTH_DECAY\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(start_epoch, start_epoch + EPOCHS):\n",
    "    s_time = time.time()\n",
    "    total_loss = 0.0\n",
    "    total_iterations_per_epoch = len(train_loader)\n",
    "    \n",
    "    for i, (sequence, labels) in enumerate(train_loader, 1):\n",
    "        #print(sequence.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        sequence = sequence.reshape(-1, 1, 25 * 3).to(device)\n",
    "        labels = labels.reshape(-1).to(device)\n",
    "        \n",
    "        #print(sequence.shape)\n",
    "        #print(labels.shape)\n",
    "        #break\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(sequence)\n",
    "        \n",
    "        #print(outputs.shape)\n",
    "        #print(labels.shape)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % PRINT_STEP == 0:\n",
    "            average_loss = total_loss / PRINT_STEP\n",
    "            print(f\"{i}/{len(train_loader)} -  Epoch [{epoch + 1}/{EPOCHS}], average_loss: {round(average_loss, 4)}\")\n",
    "            total_loss = 0.0\n",
    "\n",
    "            board_writer.add_scalar(\n",
    "                'Average_Loss/train',\n",
    "                average_loss,\n",
    "                (epoch * total_iterations_per_epoch) + i\n",
    "            )\n",
    "    \n",
    "    print(f\"Evaluation time: {time.time() - s_time}s.\")\n",
    "\n",
    "    if (epoch + 1) % SAVE_CHECHPOINT == 0:\n",
    "        save_model(model, f\"model_{epoch}\", epoch)\n",
    "\n",
    "save_model(model, \"model\", epoch)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_model(model, \"model\", epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: [0/2509]\n",
      "Processed: [49/2509]\n",
      "Processed: [98/2509]\n",
      "Processed: [147/2509]\n",
      "Processed: [196/2509]\n",
      "Processed: [245/2509]\n",
      "Processed: [294/2509]\n",
      "Processed: [343/2509]\n",
      "Processed: [392/2509]\n",
      "Processed: [441/2509]\n",
      "Processed: [490/2509]\n",
      "Processed: [539/2509]\n",
      "Processed: [588/2509]\n",
      "Processed: [637/2509]\n",
      "Processed: [686/2509]\n",
      "Processed: [735/2509]\n",
      "Processed: [784/2509]\n",
      "Processed: [833/2509]\n",
      "Processed: [882/2509]\n",
      "Processed: [931/2509]\n",
      "Processed: [980/2509]\n",
      "Processed: [1029/2509]\n",
      "Processed: [1078/2509]\n",
      "Processed: [1127/2509]\n",
      "Processed: [1176/2509]\n",
      "Processed: [1225/2509]\n",
      "Processed: [1274/2509]\n",
      "Processed: [1323/2509]\n",
      "Processed: [1372/2509]\n",
      "Processed: [1421/2509]\n",
      "Processed: [1470/2509]\n",
      "Processed: [1519/2509]\n",
      "Processed: [1568/2509]\n",
      "Processed: [1617/2509]\n",
      "Processed: [1666/2509]\n",
      "Processed: [1715/2509]\n",
      "Processed: [1764/2509]\n",
      "Processed: [1813/2509]\n",
      "Processed: [1862/2509]\n",
      "Processed: [1911/2509]\n",
      "Processed: [1960/2509]\n",
      "Processed: [2009/2509]\n",
      "Processed: [2058/2509]\n",
      "Processed: [2107/2509]\n",
      "Processed: [2156/2509]\n",
      "Processed: [2205/2509]\n",
      "Processed: [2254/2509]\n",
      "Processed: [2303/2509]\n",
      "Processed: [2352/2509]\n",
      "Processed: [2401/2509]\n",
      "Processed: [2450/2509]\n",
      "Processed: [2499/2509]\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "with torch.no_grad():\n",
    "    steps = 10\n",
    "    def_dict = {\n",
    "        \"correct\": 0,\n",
    "        \"above\": 0,\n",
    "    }\n",
    "    thresholds = [(round((1 / steps) * (i + 1), 4), def_dict.copy()) for i in range(steps)]\n",
    "    total = 0\n",
    "\n",
    "    for i, (sequence, labels) in enumerate(test_loader):\n",
    "        sequence = sequence.reshape(-1, 1, 25 * 3).to(device)\n",
    "        labels = labels.reshape(-1).to(device)\n",
    "        outputs = model(sequence)\n",
    "\n",
    "        for val_th, res_dict in thresholds:\n",
    "            res_dict[\"above\"] += (outputs.data > val_th).sum().item()\n",
    "            \n",
    "            # Correctly predicted\n",
    "            for record_i, label_i in zip(*torch.where(outputs.data > val_th)):\n",
    "                if label_i == labels[record_i]:\n",
    "                    res_dict[\"correct\"] += 1\n",
    "        \n",
    "        total += labels.size(0)\n",
    "\n",
    "        if i % 49 == 0:\n",
    "            print(f\"Processed: [{i}/{len(test_dataset)}]\")\n",
    "\n",
    "# Save dictionary results\n",
    "with open(\"model_results.json\", \"w\") as jf:\n",
    "    json.write(thresholds, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_results.json\", \"w\") as jf:\n",
    "    json.dump({\n",
    "        \"thresholds\": thresholds,\n",
    "        \"total_records\": total\n",
    "    }, jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------0.1---------------\n",
      "Test Precision: 6.3404%\n",
      "Test Recall: 86.3183%\n",
      "Test f1_score: 0.1181\n",
      "\n",
      "---------------0.2---------------\n",
      "Test Precision: 7.1934%\n",
      "Test Recall: 82.4783%\n",
      "Test f1_score: 0.1323\n",
      "\n",
      "---------------0.3---------------\n",
      "Test Precision: 7.824%\n",
      "Test Recall: 79.6995%\n",
      "Test f1_score: 0.1425\n",
      "\n",
      "---------------0.4---------------\n",
      "Test Precision: 8.3761%\n",
      "Test Recall: 77.2782%\n",
      "Test f1_score: 0.1511\n",
      "\n",
      "---------------0.5---------------\n",
      "Test Precision: 8.9114%\n",
      "Test Recall: 74.962%\n",
      "Test f1_score: 0.1593\n",
      "\n",
      "---------------0.6---------------\n",
      "Test Precision: 9.4672%\n",
      "Test Recall: 72.5032%\n",
      "Test f1_score: 0.1675\n",
      "\n",
      "---------------0.7---------------\n",
      "Test Precision: 10.0953%\n",
      "Test Recall: 69.6645%\n",
      "Test f1_score: 0.1763\n",
      "\n",
      "---------------0.8---------------\n",
      "Test Precision: 10.9018%\n",
      "Test Recall: 66.0696%\n",
      "Test f1_score: 0.1872\n",
      "\n",
      "---------------0.9---------------\n",
      "Test Precision: 12.1504%\n",
      "Test Recall: 60.1662%\n",
      "Test f1_score: 0.2022\n",
      "\n",
      "---------------1.0---------------\n",
      "Test Precision: 0%\n",
      "Test Recall: 0.0%\n",
      "Test f1_score: 0\n",
      "--------------------------------\n",
      "-------------- AP --------------\n",
      "AP: 59.2047%\n"
     ]
    }
   ],
   "source": [
    "# Calculation of evalution metrics for every threshold\n",
    "ap_score = 0\n",
    "for th, values in thresholds:\n",
    "    old_recall = 0\n",
    "\n",
    "    recall = values[\"correct\"] / total\n",
    "\n",
    "    if values[\"above\"] > 0:\n",
    "        precision = values[\"correct\"] / values[\"above\"]\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        precision = 0\n",
    "        f1_score = 0\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 15 + f\"{th}\" + \"-\" * 15)\n",
    "    print(f\"Test Precision: {round(100 * precision, 4)}%\")\n",
    "    print(f\"Test Recall: {round(100 * recall, 4)}%\")\n",
    "    print(f\"Test f1_score: {round(f1_score, 4)}\")\n",
    "\n",
    "    ap_score += (recall - old_recall) * precision\n",
    "    old_recall = recall\n",
    "\n",
    "# AP - score\n",
    "print(\"-\" * 32)\n",
    "print(\"-\" * 14 + \" AP \" + \"-\" * 14)\n",
    "print(f\"AP: {round(ap_score * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#  - evaluacne metriky\n",
    "#  - format dat pre trenovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Evalution metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "#  - Precision: the ratio of correctly annotated frames and all the model-annotated frames on test sequences\n",
    "#  - spravne anotovane (correctly annotates)\n",
    "#  - zoberiem threshold pre kazdy output v kazdom snimku --> pocet tried do ktorych sa klasifikoval snimok (all model-annotated frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
