{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-05-03T11:46:06.847512'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = \"actions-single-subject-all-POS.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_path: str):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield line.rstrip(\"\\n\")\n",
    "    yield None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action:\n",
    "    \n",
    "    NUMBER_OF_JOINTS = 25\n",
    "    NUMBER_OF_AXES = 3\n",
    "    \n",
    "    def __init__(self, sequence_id: str, label: str, start_offset: str, length: str):\n",
    "        self.seq_id = sequence_id\n",
    "        self.label = int(label)\n",
    "        self.offset = int(start_offset)\n",
    "        self.length = int(length)\n",
    "        \n",
    "        self._frames = []\n",
    "    \n",
    "    def add_frame(self, new_frame):\n",
    "        assert new_frame.shape == (self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "        self._frames.append(new_frame)\n",
    "    \n",
    "    def to_numpy(self):\n",
    "        self._frames = np.array(self._frames)\n",
    "        assert self._frames.shape == (self.length, self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "    \n",
    "    def get_header(self) -> str:\n",
    "        return f\"{self.seq_id}_{self.label}_{self.offset}_{self.length}\"\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.length\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"<Action {self.seq_id}_{self.label}_{self.offset}_{self.length} {self._frames.shape}/>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_action(file_reader, action_header: str) -> Tuple[Action, List[str]]:\n",
    "    action_lines = [action_header]\n",
    "    \n",
    "    # first header\n",
    "    action_header = action_header.split()[-1]\n",
    "    new_action = Action(\n",
    "        *action_header.split(\"_\")\n",
    "    )\n",
    "    \n",
    "    # second header\n",
    "    second_header = next(file_reader)\n",
    "    number_of_frames = int(second_header.split(\";\")[0])\n",
    "    \n",
    "    action_lines.append(second_header)\n",
    "    assert len(new_action) == number_of_frames\n",
    "    \n",
    "    # read all frames\n",
    "    for _ in range(number_of_frames):\n",
    "        line = next(file_reader)\n",
    "        frame = np.array([triple.split(\", \") for triple in line.split(\";\")], dtype=np.float32)\n",
    "        new_action.add_frame(frame)\n",
    "        action_lines.append(line)\n",
    "\n",
    "    new_action.to_numpy()\n",
    "    return new_action, action_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 500 actions\n",
      "Loaded 1000 actions\n",
      "Loaded 1500 actions\n",
      "Loaded 2000 actions\n",
      "Loaded 2500 actions\n",
      "Loaded 3000 actions\n",
      "Loaded 3500 actions\n",
      "Loaded 4000 actions\n",
      "Loaded 4500 actions\n",
      "Loaded 5000 actions\n",
      "Loaded 5500 actions\n",
      "Loaded 6000 actions\n",
      "Loaded 6500 actions\n",
      "Loaded 7000 actions\n",
      "Loaded 7500 actions\n",
      "Loaded 8000 actions\n",
      "Loaded 8500 actions\n",
      "Loaded 9000 actions\n",
      "Loaded 9500 actions\n",
      "Loaded 10000 actions\n",
      "Loaded 10500 actions\n",
      "Loaded 11000 actions\n",
      "Loaded 11500 actions\n",
      "Loaded 12000 actions\n",
      "Loaded 12500 actions\n",
      "Loaded 13000 actions\n",
      "Loaded 13500 actions\n",
      "Loaded 14000 actions\n",
      "Loaded 14500 actions\n",
      "Loaded 15000 actions\n",
      "Loaded 15500 actions\n",
      "Loaded 16000 actions\n",
      "Loaded 16500 actions\n",
      "Loaded 17000 actions\n",
      "Loaded 17500 actions\n",
      "Loaded 18000 actions\n",
      "Loaded 18500 actions\n",
      "Loaded 19000 actions\n",
      "Loaded 19500 actions\n"
     ]
    }
   ],
   "source": [
    "export_folder = os.path.join(\n",
    "    \"..\", \"data\", \"exports\",\n",
    "    f\"{os.path.splitext(FILE_NAME)[0]}_{datetime.datetime.now().isoformat()}\"\n",
    ")\n",
    "os.makedirs(export_folder)\n",
    "\n",
    "file_gen = read_file(os.path.join(\"..\", \"data\", FILE_NAME))\n",
    "\n",
    "actions = []\n",
    "new_action = None\n",
    "\n",
    "line = next(file_gen)\n",
    "while line:\n",
    "    action, action_text = read_action(file_gen, action_header=line)\n",
    "    actions.append(action)\n",
    "    \n",
    "    with open(os.path.join(export_folder, action.get_header() + \".data\"), \"w\") as f:\n",
    "        f.write('\\n'.join(action_text))\n",
    "    \n",
    "    line = next(file_gen)\n",
    "    if len(actions) % 500 == 0:\n",
    "        print(f\"Loaded {len(actions)} actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of actions: 19820\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of actions: {len(actions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch dataloader\n",
    "class MovementsDataset(Dataset):\n",
    "    \n",
    "    NUMBER_OF_JOINTS = 25\n",
    "    NUMBER_OF_AXES = 3\n",
    "    \n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.data_files = list(sorted(os.listdir(self.root)))\n",
    "        self.file_frames: List[int] = []\n",
    "        \n",
    "        # Load number of frames for every file\n",
    "        for fn in self.data_files:\n",
    "            with open(os.path.join(self.root, fn)) as f:\n",
    "                header = f.readline()\n",
    "                self.file_frames.append(\n",
    "                    int(header.split()[-1].split(\"_\")[-1])\n",
    "                )\n",
    "        \n",
    "    def _get_file_index(self, frame_indx) -> Tuple[int, int]:\n",
    "        start_indx = frame_indx\n",
    "        for i, nof in enumerate(self.file_frames):\n",
    "            if start_indx < nof:\n",
    "                # print(f\"{start_indx} - {i}\")\n",
    "                return i, start_indx\n",
    "            else:\n",
    "                start_indx -= nof\n",
    "        \n",
    "    def __getitem__(self, indx):\n",
    "        file_indx, line_indx = self._get_file_index(indx)\n",
    "        action_file = os.path.join(self.root, self.data_files[file_indx])\n",
    "        \n",
    "        with open(action_file, \"r\") as f:\n",
    "            data_str = f.read().rstrip('\\n').split('\\n')\n",
    "        \n",
    "        line_indx += 2  # first two header lines in the file   \n",
    "        frame = np.array([triple.split(\", \") for triple in data_str[line_indx].split(\";\")], dtype=np.float32)\n",
    "        assert frame.shape == (self.NUMBER_OF_JOINTS, self.NUMBER_OF_AXES)\n",
    "        \n",
    "        target = int(data_str[0].split()[-1].split(\"_\")[1])\n",
    "        \n",
    "        if self.transforms:\n",
    "            frame = self.transforms(frame)\n",
    "        \n",
    "        return frame, target\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MovementsDataset(\n",
    "    \"../data/exports/actions-single-subject-all-POS_2020-04-29T15:15:27.384264\",\n",
    "    transforms=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 - 1\n",
      "torch.Size([1, 25, 3])\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "a, b = md[143 + 24]\n",
    "print(a.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.file_frames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0002-L_11_3677_25.data'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = md.data_files[1]\n",
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#objectKey messif.objects.keys.AbstractObjectKey 0002-L_11_3677_25'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(\"../data/exports/actions-single-subject-all-POS_2020-04-29T15:15:27.384264\", fn), \"r\") as f:\n",
    "    data = f.read().split(\"\\n\")\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = DataLoader(md, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 25, 3])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for i, (images, labels) in enumerate(tl):\n",
    "    print(images.size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
